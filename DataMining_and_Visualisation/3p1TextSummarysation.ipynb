{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SummarizerPract3 (Part 1).ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVg2Shbyu_L9"
      },
      "source": [
        "CS551g Data Mining and Visualisation <br>\n",
        "Practical 3 - Text Summarisation <br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_ZcHby9wfwu"
      },
      "source": [
        "**STEP 1: Familiarize yourself with the code below**<br>\n",
        "The code builds the p(word) model in getProbabilities()\n",
        "\n",
        "\n",
        "*Use the \"files\" view on the left navigation bar to upload nokia-neg.txt and nokia-pos.txt (from NokiaTxt(Part1).zip) before runing the code below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFexN_W1boqM"
      },
      "source": [
        "import re, random, math, collections, itertools\n",
        "\n",
        "PRINT_ERRORS=0\n",
        "#calculates p(W) \n",
        "def getProbabilities(sentences, pWord):\n",
        "    freq = {} # {} initialises a dictionary [hash function]\n",
        "    allWordsTot = 0\n",
        "    #iterate through each sentence\n",
        "    for sentence in sentences:\n",
        "        wordList = re.findall(r\"[\\w']+\", sentence)\n",
        "\n",
        "        for word in wordList: #iterate over words in sentence \n",
        "            allWordsTot += 1 # keeps count of total words in dataset\n",
        "            if not (word in freq):\n",
        "                freq[word] = 1\n",
        "            else:    \n",
        "                freq[word] += 1\n",
        "\n",
        "\n",
        "        # Calculate p(word)\n",
        "    for word in freq.keys(): \n",
        "        pWord[word] = (freq[word] / float(allWordsTot) )\n",
        "\n",
        "#1. initialise datasets \n",
        "sentencesPos={};\n",
        "sentencesNeg={};\n",
        "\n",
        "file1 = \"nokia-pos.txt\"   #change this for other datasets\n",
        "file2 = \"nokia-neg.txt\"   #change this for other datasets\n",
        "\n",
        "F = open(file1, 'r', encoding=\"ISO-8859-1\")\n",
        "sentencesPos = re.split(r'\\n', F.read())\n",
        "\n",
        "F = open(file2, 'r', encoding=\"ISO-8859-1\")\n",
        "sentencesNeg = re.split(r'\\n', F.read())\n",
        "\n",
        "pWordPos={}    # p(W) \n",
        "pWordNeg={}    # p(W) \n",
        "\n",
        "#build probabilities using one of the files\n",
        "getProbabilities(sentencesPos,  pWordPos)\n",
        "getProbabilities(sentencesNeg,  pWordNeg)\n",
        "\n",
        "\n",
        "\n",
        "#query-based summary? \n",
        "#increase probability of some words in query\n",
        "\n",
        "query=[]\n",
        "#query=[\"screen\"] \n",
        "\n",
        "for word in query:\n",
        "    if (word in pWordPos):\n",
        "        pWordPos[word] *=100\n",
        "    if (word in pWordNeg):\n",
        "        pWordNeg[word] *=100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x7HYtPHTz2zo"
      },
      "source": [
        " **STEP 2: Produce summaries \n",
        "using scoreSentences()**<br>\n",
        "This function iteratively selects the highest score\n",
        "sentences till the word limit is reached<br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1_hnxuHyaiv"
      },
      "source": [
        "#summarise by selecting the sentences with the highest score\n",
        "def scoreSentences(sentences, pWord, maxLength):\n",
        "    freq = {} # {} initialises a dictionary [hash function]\n",
        "    allWordsTot = 0\n",
        "    scores = {}\n",
        "    lengths = {} \n",
        "    #iterate through each sentence\n",
        "    for sentence in sentences:\n",
        "        wordList = re.findall(r\"[\\w']+\", sentence)\n",
        "        length=1\n",
        "        score=0\n",
        "        for word in wordList: #iterate over words\n",
        "            length += 1\n",
        "            score += pWord[word]\n",
        "        scores[sentence] = score / length #calculate sentence score\n",
        "        if length <= 3: #ignore short sentences\n",
        "            scores[sentence] = 0\n",
        "        lengths[sentence] = length #calculate sentence length\n",
        "\n",
        "\n",
        "        #generate summary by incrementally including sentences in orde of importance\n",
        "    summaryLength=0\n",
        "\n",
        "    for s in sorted(scores, key=scores.get, reverse=True): #sort sentences by score\n",
        "        \n",
        "        if summaryLength + lengths[s] <=maxLength : #keep to word limit, and ignore short sentences\n",
        "            print (\"[%0.4f]\" % scores[s], s) # print sentence\n",
        "            summaryLength += lengths[s] #increment summary length\n",
        "\n",
        "    print (\"length = \", summaryLength, \" words\") \n",
        "    print (\"\")\n",
        "\n",
        "print (\"Positive Summary\")\n",
        "scoreSentences(sentencesPos, pWordPos, 100)\n",
        "\n",
        "print (\"Negative Summary\")\n",
        "scoreSentences(sentencesNeg, pWordNeg, 100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCfkdmoy0I10"
      },
      "source": [
        "**STEP 3: Produce summaries using scoreSentences2()**<br>\n",
        "\n",
        "This function iteratively selects the highest score\n",
        "sentences and updates the probabilits of words in that sentence (to prevent\n",
        "repetition of information) untill the word limit is reached<br><br>\n",
        "\n",
        "\n",
        "Are the results different? Which is better?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwg5805Nytua"
      },
      "source": [
        "#summarise by selecting the sentences with the highest score\n",
        "def scoreSentences2(sentences, pWord_original, maxLength):\n",
        "    pWord = pWord_original.copy()\n",
        "    freq = {} # {} initialises a dictionary [hash function]\n",
        "    allWordsTot = 0\n",
        "    scores = {}\n",
        "    lengths = {} \n",
        "\n",
        "    summaryLength=0\n",
        "    #main loop\n",
        "    iters=0;\n",
        "    while summaryLength<=maxLength and iters<50:\n",
        "        iters += 1\n",
        "        #recalculate scores each time\n",
        "        for sentence in sentences:\n",
        "            wordList = re.findall(r\"[\\w']+\", sentence)\n",
        "            length=1\n",
        "            score=0\n",
        "            for word in wordList: #iterate over words\n",
        "                length += 1\n",
        "                score += pWord[word]\n",
        "                \n",
        "            scores[sentence] = score / length #calculate sentence score\n",
        "            if length <= 3: #ignore short sentences\n",
        "                scores[sentence] = 0\n",
        "            lengths[sentence] = length #calculate sentence length\n",
        "\n",
        "\n",
        "        #generate summary by including best sentences and updating probabilities \n",
        "        s= max(scores, key=scores.get)\n",
        "        \n",
        "        if summaryLength  <=maxLength: #keep to word limit\n",
        "            if summaryLength + lengths[s]<=maxLength:\n",
        "                print (\"[%0.4f]\" % scores[s], s) # print sentence\n",
        "                summaryLength += lengths[s] #increment summary length\n",
        "            wordList = re.findall(r\"[\\w']+\", s)\n",
        "            for word in wordList: #iterate over words and reduce probabilities\n",
        "                pWord[word] *= pWord[word]\n",
        "            \n",
        "\n",
        "    print (\"length = \", summaryLength, \" words\") \n",
        "    print (\"\")\n",
        "\n",
        "print (\"Positive Summary\")\n",
        "scoreSentences2(sentencesPos, pWordPos, 100)\n",
        "\n",
        "print (\"Negative Summary\")\n",
        "scoreSentences2(sentencesNeg, pWordNeg, 100)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1BhI2Gly01U"
      },
      "source": [
        "#Print out n most useful predictors\n",
        "def mostUseful(pWord, n):\n",
        "    print (\"Highest Probability Words:\")\n",
        "    i=0\n",
        "    for w in sorted(pWord, key=pWord.get, reverse=True):\n",
        "        i += 1\n",
        "        if i<n:\n",
        "            print (w, \"%0.4f\" % pWord[w])\n",
        "\n",
        "#    print (\"\\nLowest Probability Words:\")\n",
        " #   i=0\n",
        "  #  for w in sorted(pWord, key=pWord.get, reverse=False):\n",
        "  #      i += 1\n",
        "   #     if i<n:\n",
        "    #        print (w, \"%0.4f\" % pWord[w])\n",
        "\n",
        "\n",
        "# print most useful words\n",
        "mostUseful(pWordPos, 50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mw-kZzPh69XW"
      },
      "source": [
        "**STEP 4: Look for the commented-out line: #query=[\"screen\"] in the first block of code and uncomment it**<br>\n",
        "All this code does is define a list of words the user is interested in (currently\n",
        "populated with \"screen\". The following lines increase the probabilities of the words\n",
        "in this list to increase the chance of their selection in the summary. <br>\n",
        "Think of some aspects to do with mobile phones and modify the query and look at\n",
        "the summaries with both summarisers.<br>\n",
        "Can you see a problem for scoreSentences2() with the query-based task? <br>"
      ]
    }
  ]
}