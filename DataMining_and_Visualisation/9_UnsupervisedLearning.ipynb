{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Practical_9_Solutions.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "evbgC8HXc9Ek"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysnd6bPNreHd"
      },
      "source": [
        "# **Lecture Day 9 Practical** - 09/03/21\n",
        "# **Contrastive Learning**\n",
        "\n",
        "Today we will explore contrastive learning, aiming to build good visual representations useful in downstream tasks in an unsupervised manners.\n",
        "\n",
        "More specifically we will be undertaking the task of replicating a recent and relevant research paper! Today we are going to implement the SimCLR network and NT-Xent Loss function from the paper:\\\n",
        "[A Simple Framework for Contrastive Learning of Visual Representations](https://arxiv.org/pdf/2002.05709.pdf)\n",
        "\n",
        "Keep this paper open during the practical so you can refer back to specific sections!\n",
        "\n",
        "---\n",
        "\n",
        "Any questions after the practical session just drop me an email:\n",
        "\n",
        "a.durrant.20@abdn.ac.uk\n",
        "\n",
        " \\- Aiden"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cAupIsaXrioT"
      },
      "source": [
        "##**Outline and Objectives:**\n",
        "Today we are going to implement the SimCLR network in keras! We are not going to exactly replicate as it will take too long for this practical session, but feel free to keep refining in your own time!\n",
        "- [ ] Construct the NT-Xent Loss Function\n",
        "- [ ] Build the training routine (siamese network & projection MLP's)\n",
        "- [ ] Build the evaluation method (linear classification)\n",
        "- [ ] View the natural semantic clusters formed via t-SNE \n",
        "\n",
        "**Extra Tasks (Not required, but extra if find this interesting)**\n",
        "- [ ] Implement a MoCo style memory bank.\n",
        "- [ ] Implement the BYOL method of training.\n",
        "\n",
        "To check off the tasks update the markdown '- [ ]' -> to '- [x]'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fut_nJQnrjY6"
      },
      "source": [
        "## **Remember!**\n",
        "Set your runtime type to allow GPU utilization!\n",
        "\n",
        "`Runtime -> Change runtime type -> GPU`\n",
        "\n",
        "If you get stuck with Colab check out the practical from Day one or have a look at these examples: \\\\\n",
        "- https://colab.research.google.com/notebooks/intro.ipynb \\\\\n",
        "- https://jupyter-notebook.readthedocs.io/en/stable/notebook.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3rB3HPGtJ78"
      },
      "source": [
        "## **Imports**\n",
        "\n",
        "Next, let us load all the appropriate modules!\n",
        "\n",
        "I have also imported a small CNN to train from my GitHub "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLkUM8em7hRX",
        "outputId": "01b95022-bf53-4a7d-d70d-65ba5a184c72"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/AidenDurrant/DMV_Practicals/master/SmallCNN.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-02-27 21:53:53--  https://raw.githubusercontent.com/AidenDurrant/DMV_Practicals/master/SmallCNN.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1622 (1.6K) [text/plain]\n",
            "Saving to: ‘SmallCNN.py.1’\n",
            "\n",
            "\rSmallCNN.py.1         0%[                    ]       0  --.-KB/s               \rSmallCNN.py.1       100%[===================>]   1.58K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-02-27 21:53:53 (24.0 MB/s) - ‘SmallCNN.py.1’ saved [1622/1622]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_uo7T7txtNUN"
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "import math\n",
        "import numpy as np\n",
        "import glob as glob # For easy pathname pattern matching\n",
        "from tqdm import tqdm # Aesthetic progress bar\n",
        "import sklearn.metrics as metrics # Easier metric definition\n",
        "from sklearn.manifold import TSNE # Dimensionality reduction for visualisation.\n",
        "from matplotlib import pyplot as plt # Plotting\n",
        "import natsort # better sorting\n",
        "import seaborn as sns\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import regularizers\n",
        "from keras import backend as K\n",
        "\n",
        "from SmallCNN import SmallCNN"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ybl7Ea6ptOOA"
      },
      "source": [
        "# **Data Loading / Pre-Processing**\n",
        "\n",
        "Let us first download the dataset we are going to use today! <br>\n",
        "\n",
        "This is the [CIFAR10](https://www.cs.toronto.edu/~kriz/cifar.html) dataset.\n",
        "<br>\n",
        "This dataset is comprised of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images.\n",
        "\n",
        "The classes:\n",
        "- airplane\n",
        "- automobile\n",
        "- bird\n",
        "- cat\n",
        "- deer\n",
        "- dog\n",
        "- frog\n",
        "- horse\n",
        "- ship\n",
        "- truck"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Rce9H8tvt09"
      },
      "source": [
        "(trainX, trainY), (testX, testY) = tf.keras.datasets.cifar10.load_data() # Download both train and test and their labels\n",
        "\n",
        "# Get the pixel intensities into range [0,1]\n",
        "trainX = trainX / 255.\n",
        "testX = testX / 255."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXJhjE3cQdS1"
      },
      "source": [
        "## **Data Augmentations**\n",
        "\n",
        "The main contribution of the SimCLR paper was the replacement of human designed pre-text tasks with \"standard\" image augmentations. \n",
        "\n",
        "Recall, each image $x$ is transformed by two random augmentation procedures ($\\tau_{1}, \\tau_{2}$) to produce two views of the same image $v_{1}$ and $v_{2}$\n",
        "\n",
        "So first we are going to define how we are going to define our augmentation procedure!\n",
        "\n",
        "I have implemented this into a class CustomAugmentation that we can call during training to produce augementations of a batch.\n",
        "\n",
        "This augmentations is inspired by my pytorch implementation, if you are interesting in the full augmentation set see [Pytorch_simclr](https://github.com/AidenDurrant/SimCLR-Pytorch)\n",
        "\n",
        "***Paper:  Section 3 - Data Augmentation for Contrastive\n",
        "Representation Learning***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1mgfPviwBDo"
      },
      "source": [
        "class CustomAugment(object):\n",
        "    def __call__(self, sample):\n",
        "        # As we are doing self-supervised learning we don;t need the label    \n",
        "        sample, _ = sample\n",
        "\n",
        "        # Randomly apply transformation (color distortions) with probability p.\n",
        "        sample = self._random_apply(self._color_jitter, sample, p=0.8)\n",
        "        sample = self._random_apply(self._color_drop, sample, p=0.2)\n",
        "\n",
        "        # Resize Crop\n",
        "        sample = tf.image.random_crop(sample, [sample.shape[0],28, 28, 3])\n",
        "        sample = tf.image.resize(sample, [32, 32])\n",
        "\n",
        "        # Random flips\n",
        "        sample = self._random_apply(tf.image.flip_left_right, sample, p=0.5)\n",
        "\n",
        "        # Normalize\n",
        "        mean=[[0.49139968, 0.48215841, 0.44653091]]\n",
        "        std=[[0.24703223, 0.24348513, 0.26158784]]\n",
        "\n",
        "        mean = tf.reshape(tf.repeat(mean, repeats=sample.shape[0] ,axis=0),[sample.shape[0],1, 1, 3]) \n",
        "        std = tf.reshape(tf.repeat(std, repeats=sample.shape[0] ,axis=0),[sample.shape[0],1, 1, 3]) \n",
        "\n",
        "        sample = (sample - mean) / (std + 1E-12)\n",
        "\n",
        "        return sample\n",
        "\n",
        "    def _color_jitter(self, x, s=0.5):\n",
        "        # one can also shuffle the order of following augmentations\n",
        "        # each time they are applied.\n",
        "        x = tf.image.random_brightness(x, max_delta=0.8*s)\n",
        "        x = tf.image.random_contrast(x, lower=1-0.8*s, upper=1+0.8*s)\n",
        "        x = tf.image.random_saturation(x, lower=1-0.8*s, upper=1+0.8*s)\n",
        "        x = tf.image.random_hue(x, max_delta=0.2*s)\n",
        "        x = tf.clip_by_value(x, 0, 1)\n",
        "        return x\n",
        "    \n",
        "    def _color_drop(self, x):\n",
        "        x = tf.image.rgb_to_grayscale(x)\n",
        "        x = tf.tile(x, [1, 1, 1, 3])\n",
        "        return x\n",
        "    \n",
        "    def _random_apply(self, func, x, p):\n",
        "        return tf.cond(\n",
        "          tf.less(tf.random.uniform([], minval=0, maxval=1, dtype=tf.float32),\n",
        "                  tf.cast(p, tf.float32)),\n",
        "          lambda: func(x),\n",
        "          lambda: x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQb0o9stxahd"
      },
      "source": [
        "# Define this class as a sequential model!\n",
        "data_augmentation = keras.Sequential([keras.layers.Lambda(CustomAugment())])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3gkkPnISkSD"
      },
      "source": [
        "# **Architecture**\n",
        "\n",
        "Now we have created the views via augmentations we now have to construct the network architecture.\n",
        "\n",
        "To keep things simple I have already created a CNN architecture for you, this can be found [here](). This is already imported so you only have to call the model `SmallCNN()`.\n",
        "\n",
        "Your task is to define the linear projection head $g(\\cdot)$ in the paper!\n",
        "\n",
        "***Paper:  Section 3 - Data Augmentation for Contrastive\n",
        "Representation Learning***\n",
        "\n",
        "[Keras Layers Documentation](https://keras.io/api/layers/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDxR80gd03Ob"
      },
      "source": [
        "!# Model\n",
        "def get_cnn(hidden_1, hidden_2):\n",
        "    base_model = SmallCNN(out_dim=10)\n",
        "    base_model.trainable = True\n",
        "    inputs = keras.layers.Input((32, 32, 3))\n",
        "    h, x = base_model(inputs)\n",
        "\n",
        "    ## TASK: YOUR CODE ##\n",
        "\n",
        "    projection_1 = keras.layers.Dense(hidden_1)(h)\n",
        "    projection_1 = keras.layers.ReLU()(projection_1)\n",
        "    projection_2 = keras.layers.Dense(hidden_2)(projection_1)\n",
        "\n",
        "    ## END ##\n",
        "\n",
        "    cnn_simclr = keras.models.Model(inputs, projection_2)\n",
        "\n",
        "    return cnn_simclr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vlPfkzCgZxtg"
      },
      "source": [
        "## **Helper Functions**\n",
        "\n",
        "Just some functions to help us with the next section!\n",
        "\n",
        "`mask_maker()` simply creates a binary mask that helps us define what is a positive and what is a negative pair of views.\n",
        "<br>\n",
        "\n",
        "`label_maker()` just returns a tensor of zeros to be used in the softmax cross entropy loss! Zero because we will have the first logit always refering to the positive pair."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhLuv0124lWm"
      },
      "source": [
        "def mask_maker(batch_size):\n",
        "  negative_mask = np.ones((batch_size, batch_size), dtype=bool)\n",
        "  for i in range(batch_size):\n",
        "    negative_mask[i, i] = 0\n",
        "  return tf.constant(negative_mask)\n",
        "\n",
        "def label_maker(batch_size):\n",
        "  return tf.zeros(batch_size*2, dtype=tf.int32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pcW5ggFRahwn"
      },
      "source": [
        "# **NT-Xent Loss**\n",
        "\n",
        "Now for the contrastive loss, your task is to implement the NT-Xent loss function defined in the SimCLR Paper:\n",
        "\n",
        "$\\ell_{i,j}=-\\log \\frac{\\exp(sim(z_i , z_j)/ \\tau)}{\\sum^{2N}_{k=1} 1_{[k\\neq i]}\\exp(sim(z_i , z_k)/ \\tau)}$\n",
        "\n",
        "where,\n",
        "\n",
        "$sim(z_i , z_j) = \\frac{z_i^{\\top}z_j}{\\|z_i\\|\\|z_j\\|}$\n",
        "\n",
        "This might look scary to implement but don't worry I will go through this with you all after you've had a go yourself!\n",
        "\n",
        "If you want some additional help unhide the following section which gives you step by step psuedo instruction on how to implement this :)\n",
        "\n",
        "***Paper:  Section 3 - Data Augmentation for Contrastive\n",
        "Representation Learning --> Equation (1)***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8r0Adw11baW"
      },
      "source": [
        "# Loss function\n",
        "def nt_xent(zis, zjs, criterion, args):\n",
        "\n",
        "  ## TASK: YOUR CODE ##\n",
        "  \n",
        "  # normalize projection feature vectors\n",
        "  zis = tf.math.l2_normalize(zis, axis=1)\n",
        "  zjs = tf.math.l2_normalize(zjs, axis=1)\n",
        "\n",
        "  aa = K.dot(zis,tf.transpose(zis)) / args['temperature']\n",
        "  bb = K.dot(zjs,tf.transpose(zjs)) / args['temperature']\n",
        "  ab = K.dot(zis,tf.transpose(zjs)) / args['temperature']\n",
        "  ba = K.dot(zjs,tf.transpose(zis)) / args['temperature']\n",
        "  \n",
        "  mask = mask_maker(args['batch_size'])\n",
        "  labels = label_maker(args['batch_size'])\n",
        "\n",
        "  # Compute Postive Logits\n",
        "  ab_pos = tf.reshape(tf.boolean_mask(ab, tf.math.logical_not(mask)), (args['batch_size'], 1))\n",
        "  ba_pos = tf.reshape(tf.boolean_mask(ba, tf.math.logical_not(mask)), (args['batch_size'], 1))\n",
        "\n",
        "  # Compute Negative Logits\n",
        "  aa_neg = tf.reshape(tf.boolean_mask(aa, mask), (args['batch_size'], -1))\n",
        "  bb_neg = tf.reshape(tf.boolean_mask(bb, mask), (args['batch_size'], -1))\n",
        "  ab_neg = tf.reshape(tf.boolean_mask(ab, mask), (args['batch_size'], -1))\n",
        "  ba_neg = tf.reshape(tf.boolean_mask(ba, mask), (args['batch_size'], -1))\n",
        "\n",
        "  # Postive Logits over all samples\n",
        "  pos = tf.concat([ab_pos, ba_pos], axis=0) \n",
        "\n",
        "  # Negative Logits over all samples\n",
        "  neg_a = tf.concat([aa_neg, ab_neg], axis=1) \n",
        "  neg_b = tf.concat([bb_neg, ba_neg], axis=1) \n",
        "\n",
        "  neg = tf.concat([neg_a, neg_b], axis=0) \n",
        "\n",
        "  # Final Logits\n",
        "  logits = tf.concat([pos, neg], axis=1) \n",
        "\n",
        "  loss = criterion(y_pred=logits, y_true=labels)\n",
        "\n",
        "  loss = loss / (2 * args['batch_size'])\n",
        "\n",
        "  ## END ##\n",
        "\n",
        "  return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evbgC8HXc9Ek"
      },
      "source": [
        " # **XT-Xent implementation steps**:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJFIzYTogmVZ"
      },
      "source": [
        "1. Normalize the representations by $\\ell_2$ norm\n",
        "2. Compute the cosine similarity between all views. (matrix multiplication `K.dot(a,b)`)\n",
        "\n",
        "**Note:**\n",
        "\n",
        "Cosine similarity matrix of all samples in batch:\n",
        "  a = $z_i$\n",
        "  b = $z_j$\n",
        "```\n",
        "How the similarity matrix will look after a matrix multiplication of the representations.\n",
        "    ____ ____\n",
        "  | aa | ab |\n",
        "  |____|____|\n",
        "  | ba | bb |\n",
        "  |____|____|\n",
        "```\n",
        "\n",
        "  Postives:\n",
        "  Leading diagonals of ab and ba `'\\'`\n",
        "\n",
        "  Negatives:\n",
        "  All values that do not lie on leading diagonals of aa, bb, ab, ba.\n",
        "\n",
        "3. Divide by our temperature $\\tau$\n",
        "4. Retrieve a mask and our labels from our helper functions\n",
        "5. Get the similarities previously computed for the **positive** pairs. (Leading diagonals of our similarity matrix, use our mask!)\n",
        "6. Get the similarities previously computed for the **negative** pairs. (off the leading diagonals of our similarity matrix, use our mask!)\n",
        "7. concatenate all our positives together, and concatenate all our negatives together.\n",
        "8. concatenate our postive and negatives together ensuringt that the positive is ordered first!\n",
        "9. Take this concatenation and run through a cross_entropy loss with our labels from the helper function! (We've already passed this as `criterion`)\n",
        "\n",
        "[Normalise Docs](https://www.tensorflow.org/api_docs/python/tf/math/l2_normalize)\n",
        "\n",
        "[Transpose Docs](https://www.tensorflow.org/api_docs/python/tf/transpose)\n",
        "\n",
        "[Boolean Mask Docs](https://www.tensorflow.org/api_docs/python/tf/boolean_mask)\n",
        "\n",
        "[logical not Docs](https://www.tensorflow.org/api_docs/python/tf/math/logical_not)\n",
        "\n",
        "[reshape Docs](https://www.tensorflow.org/api_docs/python/tf/reshape)\n",
        "\n",
        "[concatenate Docs](https://www.tensorflow.org/api_docs/python/tf/concat)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zsvjngfUgnxW"
      },
      "source": [
        "# **Training Method**\n",
        "\n",
        "Given the nature of the SimCLR model we need a little more control for running the training loop, ususally we use `model.fit()` however in this case we manually run the training loop!\n",
        "\n",
        "Your task today is to complete the training loop! I have missed a few steps out that directly relate to the SimCLR model. Psuedo-code is provided in the paper this can help you!\n",
        "\n",
        "**Paper: Section 2 - Method --> Algorithm (1)**\n",
        "\n",
        "What I have given you is the general training routing for a custom training loop in Keras, this can be applied to any model!\n",
        "\n",
        "**Tip:** \n",
        "<br>\n",
        "We have just defined lots of functions that make up SimCLR, let's put them to use!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0Ka2znl1jJ1"
      },
      "source": [
        "def train_simclr(model, dataset, args):\n",
        "    epoch_wise_loss = []\n",
        "    step_wise_loss = []\n",
        "\n",
        "    # Our cross entroopy loss used in the NT_Xent loss we previously implemented!\n",
        "    criterion = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction=tf.keras.losses.Reduction.SUM)\n",
        "\n",
        "    # Learning rate decay during training\n",
        "    decay_steps = 1000\n",
        "    lr_decayed_fn = tf.keras.experimental.CosineDecay(initial_learning_rate=args['lr'], decay_steps=decay_steps)\n",
        "\n",
        "    # optimizer\n",
        "    optimizer = tf.keras.optimizers.SGD(lr_decayed_fn)\n",
        "\n",
        "    # Batch the dataset dropping batches that are not len(`batch_size`)\n",
        "    dataset = dataset.batch(args['batch_size'], drop_remainder=True)\n",
        "\n",
        "    # iterate over epochs\n",
        "    for epoch in range(args['epochs']):\n",
        "        # Shuffle training set at each epoch\n",
        "        dataset = dataset.shuffle(buffer_size=1024)\n",
        "        print(\"\\n Epoch: {}\\n\".format(epoch))\n",
        "\n",
        "        # Iterate over all batches in the training set!\n",
        "        for image_batch in dataset:\n",
        "\n",
        "            ## TASK: YOUR CODE ##\n",
        "\n",
        "            # Create the views of the images in image_batch\n",
        "            a = data_augmentation(image_batch)\n",
        "            b = data_augmentation(image_batch)\n",
        "\n",
        "            # Record the operations so we can compute the gradient \n",
        "            with tf.GradientTape() as tape:\n",
        "\n",
        "              # Pass to the model\n",
        "              zis = model(a)\n",
        "              zjs = model(b)\n",
        "\n",
        "              # Compute the loss!\n",
        "              loss = nt_xent(zis, zjs, criterion, args)\n",
        "\n",
        "              ## END ##\n",
        "\n",
        "              # keep track of our loss\n",
        "              step_wise_loss.append(loss)\n",
        "\n",
        "            # Compute the gradients of the model and step with our optimiser\n",
        "            gradients = tape.gradient(loss, model.trainable_variables)\n",
        "            optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "        # keep track of our epoch loss\n",
        "        epoch_wise_loss.append(np.mean(step_wise_loss))\n",
        "        \n",
        "        # save the latest model weights\n",
        "        model.save_weights(\"./checkpoint/cp.ckpt\")\n",
        "\n",
        "        if epoch % 1 == 0:\n",
        "            print(\"epoch: {} loss: {:.3f}\".format(epoch + 1, np.mean(step_wise_loss)))\n",
        "\n",
        "    return epoch_wise_loss, model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oslTrGAmg0n-"
      },
      "source": [
        "# **Run!**\n",
        "\n",
        "Great, now we have all the components to train the self-supervised SimCLR network!\n",
        "\n",
        "We will put them all together now, load our model, pass it and the hyperparameters(`args`) to our train loop along with our dataset!\n",
        "\n",
        "Tips for training SimCLR are also in the paper!\n",
        "\n",
        "**Paper: Appendix B.9 - CIFAR10**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-nOkwY_-nAV"
      },
      "source": [
        "tf.get_logger().setLevel('ERROR')\n",
        "\n",
        "# HyperParams\n",
        "args = {'epochs': 50, 'batch_size': 256, 'lr': 1.0, 'temperature':0.5}\n",
        "\n",
        "# Load our encoder\n",
        "cnn_simclr = get_cnn(512, 128)\n",
        "cnn_simclr.summary()\n",
        "\n",
        "# Take the numpy dataset and make a TF dataset\n",
        "dataset = tf.data.Dataset.from_tensor_slices((trainX, trainY))\n",
        "\n",
        "# Self-supervised training!\n",
        "epoch_loss, model = train_simclr(cnn_simclr, dataset, args)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvquRsnLrPNf"
      },
      "source": [
        "# **Linear Evaluation!**\n",
        "\n",
        "Now we have trained our network and saved our latest weights, we now have to evaluate the weights as to determine if we have learnt good image representations! (Refer back to the lecture if this doesn't make sense).\n",
        "\n",
        "First lets start by simply making a linear classifer (i.e. the last softmax classification layer with 10 classes!)\n",
        "\n",
        "[Layer Documentation](https://keras.io/api/layers/core_layers/dense/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnZDztqOr0xx"
      },
      "source": [
        "def linear_classifier(num_classes, features):\n",
        "    ## TASK: YOUR CODE ##\n",
        "\n",
        "    linear_model = keras.models.Sequential([keras.layers.Dense(num_classes, input_shape=(features, ), activation=\"softmax\")])\n",
        "\n",
        "    ## END ##\n",
        "\n",
        "    return linear_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h32Vl2EzksKi"
      },
      "source": [
        "### **Train the Classifier**\n",
        "\n",
        "Using what you've seen from training the self-supervised training above I want you to define the encoder, load the model and freeze the encoder weights.\n",
        "\n",
        "[Trainable Weights Documentation](https://keras.io/api/layers/base_layer/#trainable_weights-property)\n",
        "\n",
        "Once we've loaded the self-supervised weights we can now compute the representations of the data that we are going to use to train the classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNlLrdB6rR_p"
      },
      "source": [
        "# HyperParams\n",
        "tf.get_logger().setLevel('ERROR')\n",
        "args = {'epochs': 50, 'batch_size': 256, 'lr': 0.1}\n",
        "\n",
        "## TASK: YOUR CODE ##\n",
        "cnn_simclr = get_cnn(512, 128)\n",
        "cnn_simclr.load_weights(\"./checkpoint/cp.ckpt\")\n",
        "\n",
        "cnn_simclr.layers[1].trainable = False\n",
        "cnn_simclr.summary()\n",
        "\n",
        "## END ##\n",
        "\n",
        "# Define the model to output the layer before the MLP projection head g(.)\n",
        "projection = keras.models.Model(cnn_simclr.input, cnn_simclr.layers[-4].output)\n",
        "\n",
        "\n",
        "# Load the data from numpy to TF dataset\n",
        "dataset = tf.data.Dataset.from_tensor_slices((trainX, trainY))\n",
        "\n",
        "# Produce the representations of the dataset from the frozen self-supervised encoder\n",
        "train_features, _ = projection.predict(trainX)\n",
        "test_features, _ = projection.predict(testX)\n",
        "\n",
        "# Early stopping, you can change this as you see fit!\n",
        "es = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=2, verbose=2, restore_best_weights=True)\n",
        "\n",
        "# Initialise our classifier from above!\n",
        "linear_model = linear_classifier(10, 256)\n",
        "\n",
        "# Train using the standard keras method only training the classifier from the \n",
        "# representations produced from the self-supervised encoder!\n",
        "linear_model.compile(loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"],\n",
        "                     optimizer=\"adam\")\n",
        "history = linear_model.fit(train_features, trainY,\n",
        "                 validation_data=(test_features, testY),\n",
        "                 batch_size=64,\n",
        "                 epochs=35,\n",
        "                 callbacks=[es])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ea1eq_B1mzIX"
      },
      "source": [
        "## **Visualise the Representations**\n",
        "\n",
        "Now we have finished training our model, we want to see how our representations are distributed in space in relation to the semantic classes they belong to! Remember these representations were learnt in an self-supervised manner with no semantic labels!\n",
        "\n",
        "We feed our previously computed representations from the frozen encoder, yet as these are high-dimensional we need a method to appropriately visualise them.\n",
        "\n",
        "To visualise this high-dimensional vector we will employ [t-SNE](https://jmlr.org/papers/volume9/vandermaaten08a/vandermaaten08a.pdf) a unsupervised dimensionality reduction method!\n",
        "\n",
        "Once in a more manageable dimension (2 dimensions (x,y)) we will plot the representations with their corresponding true semantic label.\n",
        "\n",
        "Your task is to simply perform the t-SNE visualisation, and plot the tsne representations with their corresponding true semantic label! You can use a pre-built package.\n",
        "\n",
        "[t-SNE scikitlearn Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html)\n",
        "\n",
        "[seaborn scatter plot](https://seaborn.pydata.org/generated/seaborn.scatterplot.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "McQrn7N6E5Bw"
      },
      "source": [
        "## TASK: YOUR CODE ##\n",
        "\n",
        "# TSNE of representations\n",
        "v = TSNE(n_components=2).fit_transform(train_features)\n",
        "\n",
        "# Plot the tsne representations with their corresponding true semantic label!\n",
        "fig = plt.figure(figsize = (10, 10))\n",
        "sns.set_style(\"darkgrid\")\n",
        "sns.scatterplot(v[:,0], v[:,1], hue=trainY[:,0], legend='full', palette=sns.color_palette(\"bright\", 10))\n",
        "plt.show()\n",
        "\n",
        "## END ##"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKRuNlhlqru6"
      },
      "source": [
        "## **That's all**\n",
        "\n",
        "So today's practical session has asked you to implement the main elements of a relevant and important paper outlining a key method in the field of self-supervised learning! I hope you gained a greater understanding of how these contrastive methods work now you have implemented them!\n",
        "\n",
        "\n",
        "If you're interested in this research field check out some other works:\n",
        "- [BYOL](https://arxiv.org/abs/2006.07733)\n",
        "- [MoCo](https://arxiv.org/abs/1911.05722)\n",
        "- [SimCLR v2](https://arxiv.org/abs/2006.10029)\n",
        "\n",
        "And if you still have time or want to work on this in your own time try out the bonus tasks listed at the top of this notebook :)\n",
        "\n",
        "I hope you enjoyed this type of practical replicating papers!\n",
        "\n",
        "\\- Aiden\n",
        "\n",
        "## **References**\n",
        "\n",
        "https://github.com/AidenDurrant/SimCLR-Pytorch/\n",
        "\n",
        "https://github.com/sayakpaul/SimCLR-in-TensorFlow-2\n",
        "\n"
      ]
    }
  ]
}