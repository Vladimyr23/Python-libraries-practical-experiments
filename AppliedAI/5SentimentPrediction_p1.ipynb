{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# University of Aberdeen\n",
    "\n",
    "## Applied AI (CS5079)\n",
    "\n",
    "### Lecture (Day 5) - Investigating Sentiment Prediction\n",
    "\n",
    "---\n",
    "\n",
    "In the lecture, we cover tools for pre-processing text data, several supervised/unsupervised models for sentiment prediction and model causation.  This lecture is inspired by Chapter 7 of __Practical Machine Learning with Python__ (2018), Sarkar et al.\n",
    "\n",
    "__In this particular notebook, we normalize the dataset and investigate multiple unsupervised lexion-based models__.\n",
    "\n",
    "We will use the following packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usual data representation and manipulation libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "# NLTK is very useful for natural language applications\n",
    "import nltk\n",
    "\n",
    "# This will be used to tokenize sentences\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "\n",
    "# We use spacy for extracting useful information from English words\n",
    "import spacy\n",
    "nlp = spacy.load('en', parse = False, tag=False, entity=False)\n",
    "\n",
    "# This dictionary will be used to expand contractions (e.g. we'll -> we will)\n",
    "from contractions import contractions_dict\n",
    "import re\n",
    "\n",
    "# Unicodedata will be used to remove accented characters\n",
    "import unicodedata\n",
    "\n",
    "# BeautifulSoup will be used to remove html tags\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Lexicon models\n",
    "from afinn import Afinn\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "# Evaluation libraries\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the dataset and Pre-Processing\n",
    "\n",
    "We will predict the sentiment for movie reviews obtained from the Internet Movie Database (IMDb). The dataset contains 50,000 movie reviews that have been labeled with “positive” and “negative” labels based on the review content.\n",
    "\n",
    "If you are not using Codio, the dataset can be obtained from http://ai.stanford.edu/~amaas/data/sentiment/, courtesy of Stanford University and Andrew L. Maas, Raymond E. Daly, Peter T. Pham, Dan Huang, Andrew Y. Ng, and Christopher Potts. This dataset was also used in their paper: \"Learning Word Vectors for Sentiment Analysis proceedings of the 49th Annual Meeting of the Association\" for Computational Linguistics (ACL 2011)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We import the dataset\n",
    "movie_reviews_raw = pd.read_csv(\"Datasets/movie_reviews.csv\")\n",
    "movie_reviews_raw.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous sample, you can notice that the text reviews contain html tag. The following code will use `BeautifulSoup` to remove those tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_html_tags(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    stripped_text = soup.get_text()\n",
    "    return stripped_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It may also be important to remove accented and special characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_accented_chars(text):\n",
    "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "    return text\n",
    "\n",
    "def remove_special_characters(text):\n",
    "    text = re.sub('[^a-zA-z0-9\\s]', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below will use `contractions` dictionary to find contractions (using regular expressions) and expand them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_contractions(text, contraction_mapping=contractions_dict):\n",
    "    \n",
    "    contractions_pattern = re.compile('({})'.format('|'.join(contractions_dict.keys())), \n",
    "                                      flags=re.IGNORECASE|re.DOTALL)\n",
    "\n",
    "    def expand_match(contraction):\n",
    "        match = contraction.group(0)\n",
    "        first_char = match[0]\n",
    "        expanded_contraction = contraction_mapping.get(match) if contraction_mapping.get(match) else contraction_mapping.get(match.lower())                               \n",
    "        return first_char+expanded_contraction[1:] if expanded_contraction != None else match\n",
    "        \n",
    "    expanded_text = contractions_pattern.sub(expand_match, text)\n",
    "    expanded_text = re.sub(\"'\", \"\", expanded_text)\n",
    "    return expanded_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on the application, we may also need to lemmatize the words in a sentence, i.e. extract the canonical form of the words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_text(text):\n",
    "    text = nlp(text)\n",
    "    return ' '.join([word.lemma_ if word.lemma_ != '-PRON-' else word.text for word in text])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We download a list of stopwords (list of words that are usually filtered before processing natural languages). Because we are concerned with sentiment prediction, it is very important to keep the polarity of the sentence, that is why we need to keep words like `no` or `not`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('stopwords')\n",
    "stopword_list = nltk.corpus.stopwords.words('english')\n",
    "stopword_list.remove('no')\n",
    "stopword_list.remove('not')\n",
    "\n",
    "def remove_stopwords(text, is_lower_case=False):\n",
    "    tokenizer = ToktokTokenizer()\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    tokens = [token.strip() for token in tokens]\n",
    "    \n",
    "    if is_lower_case:\n",
    "        filtered_tokens = [token for token in tokens if token not in stopword_list]\n",
    "    else:\n",
    "        filtered_tokens = [token for token in tokens if token.lower() not in stopword_list]\n",
    "    filtered_text = ' '.join(filtered_tokens)    \n",
    "    return filtered_text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now combine all the previous functions into a `normalize_corpus` function to apply the chosen pre-processing techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_corpus(corpus, html_stripping=True, contraction_expansion=True,\n",
    "                     accented_char_removal=True, text_lower_case=True, \n",
    "                     text_lemmatization=True, special_char_removal=True, \n",
    "                     stopword_removal=True):\n",
    "    \n",
    "    normalized_corpus = []\n",
    "    # normalize each document in the corpus\n",
    "    for doc in corpus:\n",
    "        # strip HTML\n",
    "        if html_stripping:\n",
    "            doc = strip_html_tags(doc)\n",
    "        # remove accented characters\n",
    "        if accented_char_removal:\n",
    "            doc = remove_accented_chars(doc)\n",
    "        # expand contractions    \n",
    "        if contraction_expansion:\n",
    "            doc = expand_contractions(doc)\n",
    "        # lowercase the text    \n",
    "        if text_lower_case:\n",
    "            doc = doc.lower()\n",
    "        # remove extra newlines\n",
    "        doc = re.sub(r'[\\r|\\n|\\r\\n]+', ' ',doc)\n",
    "        # insert spaces between special characters to isolate them    \n",
    "        special_char_pattern = re.compile(r'([{.(-)!}])')\n",
    "        doc = special_char_pattern.sub(\" \\\\1 \", doc)\n",
    "        # lemmatize text\n",
    "        if text_lemmatization:\n",
    "            doc = lemmatize_text(doc)\n",
    "        # remove special characters    \n",
    "        if special_char_removal:\n",
    "            doc = remove_special_characters(doc)  \n",
    "        # remove extra whitespace\n",
    "        doc = re.sub(' +', ' ', doc)\n",
    "        # remove stopwords\n",
    "        if stopword_removal:\n",
    "            doc = remove_stopwords(doc, is_lower_case=text_lower_case)\n",
    "            \n",
    "        normalized_corpus.append(doc)\n",
    "    return normalized_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can run the following code snippet to convert and save the processed dataset or use the `normalized_movie_reviews.csv` file directly. This step may take some time to be completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#movie_reviews_raw['review'] = normalize_corpus(movie_reviews_raw.review)\n",
    "#movie_reviews_raw.to_csv(\"normalized_movie_reviews.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one reviewer mention watch 1 oz episode hook r...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wonderful little production filming technique ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>think wonderful way spend time hot summer week...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically family little boy jake think zombie ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter matteis love time money visually stunni...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  one reviewer mention watch 1 oz episode hook r...  positive\n",
       "1  wonderful little production filming technique ...  positive\n",
       "2  think wonderful way spend time hot summer week...  positive\n",
       "3  basically family little boy jake think zombie ...  negative\n",
       "4  petter matteis love time money visually stunni...  positive"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_movie_reviews = pd.read_csv(\"Datasets/normalized_movie_reviews.csv\")\n",
    "normalized_movie_reviews.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised Lexicon-based Models\n",
    "\n",
    "We split the dataset into a training (resp. test) dataset containing the first 35,000 (resp. last 15,000) instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = np.array(normalized_movie_reviews['review'])\n",
    "sentiments = np.array(normalized_movie_reviews['sentiment'])\n",
    "\n",
    "# extract data for model evaluation\n",
    "test_reviews = reviews[35000:]\n",
    "train_reviews = reviews[:35000]\n",
    "test_sentiments = sentiments[35000:]\n",
    "train_sentiments = sentiments[:35000]\n",
    "\n",
    "sample_review_ids = [7626, 3533, 13010]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AFINN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell, we show how AFINN can easily score the polarity of a review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REVIEW: no comment stupid movie act average bad screenplay no sense skip\n",
      "Actual Sentiment: negative\n",
      "Predicted Sentiment polarity: -7.0\n",
      "------------------------------------------------------------\n",
      "REVIEW: not care people vote movie bad want truth good movie every thing movie really get one\n",
      "Actual Sentiment: positive\n",
      "Predicted Sentiment polarity: 3.0\n",
      "------------------------------------------------------------\n",
      "REVIEW: bad horror film ever funniest film ever roll one get see film cheap unbeliaveble see really p watch carrot\n",
      "Actual Sentiment: positive\n",
      "Predicted Sentiment polarity: -3.0\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "afn = Afinn(emoticons=True)\n",
    "\n",
    "for review, sentiment in zip(test_reviews[sample_review_ids], test_sentiments[sample_review_ids]):\n",
    "    print('REVIEW:', review)\n",
    "    print('Actual Sentiment:', sentiment)\n",
    "    print('Predicted Sentiment polarity:', afn.score(review))\n",
    "    print('-'*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next two cells, we evaluate our sentiment prediction model with AFINN on the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = lambda x: \"positive\" if x else \"negative\"\n",
    "y_predicted = [T(x) for x in [afn.score(review)>=0 for review in test_reviews]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model accuracy score is: 0.7084666666666667\n",
      "The model precision score is: 0.7305592613010629\n",
      "The model recall score is: 0.7084666666666667\n",
      "The model F1-score is: 0.7012126290280828\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.55      0.65      7490\n",
      "    positive       0.66      0.86      0.75      7510\n",
      "\n",
      "    accuracy                           0.71     15000\n",
      "   macro avg       0.73      0.71      0.70     15000\n",
      "weighted avg       0.73      0.71      0.70     15000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pred. negative</th>\n",
       "      <th>Pred. positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Act. negative</th>\n",
       "      <td>4140</td>\n",
       "      <td>3350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Act. positive</th>\n",
       "      <td>1023</td>\n",
       "      <td>6487</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Pred. negative  Pred. positive\n",
       "Act. negative            4140            3350\n",
       "Act. positive            1023            6487"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"The model accuracy score is: {}\".format(accuracy_score(test_sentiments, y_predicted)))\n",
    "print(\"The model precision score is: {}\".format(precision_score(test_sentiments, y_predicted, average=\"weighted\")))\n",
    "print(\"The model recall score is: {}\".format(recall_score(test_sentiments, y_predicted, average=\"weighted\")))\n",
    "print(\"The model F1-score is: {}\".format(f1_score(test_sentiments, y_predicted, average=\"weighted\")))\n",
    "\n",
    "print(classification_report(test_sentiments, y_predicted))\n",
    "\n",
    "display(pd.DataFrame(confusion_matrix(test_sentiments, y_predicted), columns=[\"Pred. negative\", \"Pred. positive\"], index=[\"Act. negative\", \"Act. positive\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SentiWordNet\n",
    "\n",
    "Wordnet groupes synonyms into synsets with short definitions and usage examples. In the example below, we print the synsets for the word `extravagant`. You can notice than each synset is associated with a positive, a negative and an objectivity score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Synset</th>\n",
       "      <th>Definition</th>\n",
       "      <th>Positive Polarity</th>\n",
       "      <th>Negative Polarity</th>\n",
       "      <th>Objectivity Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Synset('excessive.s.02')</td>\n",
       "      <td>unrestrained, especially with regard to feelings</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Synset('extravagant.s.02')</td>\n",
       "      <td>recklessly wasteful</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Synset  \\\n",
       "0    Synset('excessive.s.02')   \n",
       "1  Synset('extravagant.s.02')   \n",
       "\n",
       "                                         Definition  Positive Polarity  \\\n",
       "0  unrestrained, especially with regard to feelings              0.125   \n",
       "1                               recklessly wasteful              0.000   \n",
       "\n",
       "   Negative Polarity  Objectivity Score  \n",
       "0              0.375              0.500  \n",
       "1              0.125              0.875  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extravant = list(swn.senti_synsets('extravagant', 'a'))\n",
    "pd.DataFrame.from_dict({ \"Synset\" : [ s.synset for s in extravant],\n",
    "\"Definition\" : [s.synset.definition() for s in extravant], \"Positive Polarity\" : [s._pos_score for s in extravant], \"Negative Polarity\" : [s._neg_score for s in extravant], \"Objectivity Score\" : [s._obj_score for s in extravant]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create a simple function to aggregate the scores of the most common synsets for the words in the reviews using the postive and negative scores returned by Wordnet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sentiment_sentiwordnet_lexicon(review):\n",
    "    # tokenize and POS tag text tokens\n",
    "    tagged_text = [(token.text, token.tag_) for token in nlp(review)]\n",
    "    pos_score = neg_score = token_count = obj_score = 0\n",
    "    # get wordnet synsets based on POS tags\n",
    "    # get sentiment scores if synsets are found\n",
    "    for word, tag in tagged_text:\n",
    "        ss_set = None\n",
    "        if 'NN' in tag and list(swn.senti_synsets(word, 'n')): #NOUNS\n",
    "            ss_set = list(swn.senti_synsets(word, 'n'))[0]\n",
    "        elif 'VB' in tag and list(swn.senti_synsets(word, 'v')): #VERBS\n",
    "            ss_set = list(swn.senti_synsets(word, 'v'))[0]\n",
    "        elif 'JJ' in tag and list(swn.senti_synsets(word, 'a')): #ADJECTIVES\n",
    "            ss_set = list(swn.senti_synsets(word, 'a'))[0]\n",
    "        elif 'RB' in tag and list(swn.senti_synsets(word, 'r')): #ADVERBS\n",
    "            ss_set = list(swn.senti_synsets(word, 'r'))[0]\n",
    "        # if senti-synset is found        \n",
    "        if ss_set:\n",
    "            # add scores for all found synsets\n",
    "            pos_score += ss_set.pos_score()\n",
    "            neg_score += ss_set.neg_score()\n",
    "            obj_score += ss_set.obj_score()\n",
    "            token_count += 1\n",
    "    \n",
    "    # aggregate final scores\n",
    "    final_score = pos_score - neg_score\n",
    "    norm_final_score = round(float(final_score) / token_count, 2)\n",
    "    return norm_final_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REVIEW: no comment stupid movie act average bad screenplay no sense skip\n",
      "Actual Sentiment: negative\n",
      "Predicted Sentiment polarity: -0.1\n",
      "------------------------------------------------------------\n",
      "REVIEW: not care people vote movie bad want truth good movie every thing movie really get one\n",
      "Actual Sentiment: positive\n",
      "Predicted Sentiment polarity: 0.11\n",
      "------------------------------------------------------------\n",
      "REVIEW: bad horror film ever funniest film ever roll one get see film cheap unbeliaveble see really p watch carrot\n",
      "Actual Sentiment: positive\n",
      "Predicted Sentiment polarity: 0.03\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for review, sentiment in zip(test_reviews[sample_review_ids], test_sentiments[sample_review_ids]):\n",
    "    print('REVIEW:', review)\n",
    "    print('Actual Sentiment:', sentiment)\n",
    "    print('Predicted Sentiment polarity: '+ str(analyze_sentiment_sentiwordnet_lexicon(review)))\n",
    "    print('-'*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = [T(x) for x in [analyze_sentiment_sentiwordnet_lexicon(review)>=0 for review in test_reviews]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model accuracy score is: 0.6842666666666667\n",
      "The model precision score is: 0.6869568255259471\n",
      "The model recall score is: 0.6842666666666667\n",
      "The model F1-score is: 0.683079703654126\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.62      0.66      7490\n",
      "    positive       0.66      0.75      0.70      7510\n",
      "\n",
      "    accuracy                           0.68     15000\n",
      "   macro avg       0.69      0.68      0.68     15000\n",
      "weighted avg       0.69      0.68      0.68     15000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pred. negative</th>\n",
       "      <th>Pred. positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Act. negative</th>\n",
       "      <td>4668</td>\n",
       "      <td>2822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Act. positive</th>\n",
       "      <td>1914</td>\n",
       "      <td>5596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Pred. negative  Pred. positive\n",
       "Act. negative            4668            2822\n",
       "Act. positive            1914            5596"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"The model accuracy score is: {}\".format(accuracy_score(test_sentiments, y_predicted)))\n",
    "print(\"The model precision score is: {}\".format(precision_score(test_sentiments, y_predicted, average=\"weighted\")))\n",
    "print(\"The model recall score is: {}\".format(recall_score(test_sentiments, y_predicted, average=\"weighted\")))\n",
    "print(\"The model F1-score is: {}\".format(f1_score(test_sentiments, y_predicted, average=\"weighted\")))\n",
    "\n",
    "print(classification_report(test_sentiments, y_predicted))\n",
    "\n",
    "display(pd.DataFrame(confusion_matrix(test_sentiments, y_predicted), columns=[\"Pred. negative\", \"Pred. positive\"], index=[\"Act. negative\", \"Act. positive\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VADER Lexicon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VADER (Valence Aware Dictionary for Sentiment Reasoning) is a model used for text sentiment analysis that is sensitive to both polarity (positive/negative) and intensity (strength) of emotion. It is available in the NLTK package and can be applied directly to unlabeled text data.\n",
    "\n",
    "In the next cell, we can see that VADER returns four sentiment scores `compound`, `neg`, `neu` and `pos`. In the following model, we will only use the `compound` (i.e. the aggregated score)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'compound': -0.6759, 'neg': 0.41, 'neu': 0.59, 'pos': 0.0}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()\n",
    "analyzer.polarity_scores('This movie was actually neither that funny, nor super witty.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sentiment_vader_lexicon(review, threshold=0.1):\n",
    "    # analyze the sentiment for review\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    scores = analyzer.polarity_scores(review)\n",
    "    # get aggregate scores and final sentiment\n",
    "    agg_score = scores['compound']\n",
    "    final_sentiment = 'positive' if agg_score >= threshold else 'negative'\n",
    "    return final_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REVIEW: no comment stupid movie act average bad screenplay no sense skip\n",
      "Actual Sentiment: negative\n",
      "------------------------------------------------------------\n",
      "REVIEW: not care people vote movie bad want truth good movie every thing movie really get one\n",
      "Actual Sentiment: positive\n",
      "------------------------------------------------------------\n",
      "REVIEW: bad horror film ever funniest film ever roll one get see film cheap unbeliaveble see really p watch carrot\n",
      "Actual Sentiment: positive\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for review, sentiment in zip(test_reviews[sample_review_ids], test_sentiments[sample_review_ids]):\n",
    "    print('REVIEW:', review)\n",
    "    print('Actual Sentiment:', sentiment)\n",
    "    pred = analyze_sentiment_vader_lexicon(review, threshold=0.4)    \n",
    "    print('-'*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model accuracy score is: 0.7043333333333334\n",
      "The model precision score is: 0.7131634140041795\n",
      "The model recall score is: 0.7043333333333334\n",
      "The model F1-score is: 0.7011709547819932\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.60      0.67      7490\n",
      "    positive       0.67      0.81      0.73      7510\n",
      "\n",
      "    accuracy                           0.70     15000\n",
      "   macro avg       0.71      0.70      0.70     15000\n",
      "weighted avg       0.71      0.70      0.70     15000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pred. negative</th>\n",
       "      <th>Pred. positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Act. negative</th>\n",
       "      <td>4506</td>\n",
       "      <td>2984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Act. positive</th>\n",
       "      <td>1451</td>\n",
       "      <td>6059</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Pred. negative  Pred. positive\n",
       "Act. negative            4506            2984\n",
       "Act. positive            1451            6059"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_predicted = [analyze_sentiment_vader_lexicon(review, threshold=0.4) for review in test_reviews]\n",
    "\n",
    "print(\"The model accuracy score is: {}\".format(accuracy_score(test_sentiments, y_predicted)))\n",
    "print(\"The model precision score is: {}\".format(precision_score(test_sentiments, y_predicted, average=\"weighted\")))\n",
    "print(\"The model recall score is: {}\".format(recall_score(test_sentiments, y_predicted, average=\"weighted\")))\n",
    "print(\"The model F1-score is: {}\".format(f1_score(test_sentiments, y_predicted, average=\"weighted\")))\n",
    "\n",
    "print(classification_report(test_sentiments, y_predicted))\n",
    "\n",
    "display(pd.DataFrame(confusion_matrix(test_sentiments, y_predicted), columns=[\"Pred. negative\", \"Pred. positive\"], index=[\"Act. negative\", \"Act. positive\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
